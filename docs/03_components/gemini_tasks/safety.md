# 安全性検証タスク (Safety Validation)

本ドキュメントは、生成されたテキストの安全性や適切性を判定する検証タスクの仕様を定義する。

## 1. スポイラー判定 (check_spoiler)

### 1.1 目的
生成されたテキストが、未視聴のユーザーにとって致命的な「ネタバレ（試合結果）」を含んでいないか判定する。

### 1.2 プロンプト仕様

**現行プロンプト**:
```
以下のテキストが「{home_team} vs {away_team}」の試合結果を言及しているかを判定してください。

テキスト:
{text[:1500]}

判定基準:
- スコア（例: 2-1, 3-0）の記載
- 勝敗の記載（例: 〇〇が勝利、敗北、won, lost）
- ゴールを決めた選手名（得点者）

回答は以下のJSON形式のみで（説明不要）:
{"is_safe": true, "reason": "なし"} または {"is_safe": false, "reason": "理由"}
```

### 1.3 実装ポイント
- **クライアント**: SDK (`google-generativeai`)
- **モデル**: `gemini-pro-latest`
- **出力**: JSON固定 `{"is_safe": boolean, "reason": string}`
- **入力制限**: 1500文字（コンテキストウィンドウ節約と速度重視のため冒頭部分等を判定）

### 1.4 判定基準の詳細
- **False Positive（誤検知）**: 安全なのに危険と判定すること。システムは警告を出すが、ユーザー体験への悪影響は限定的。
- **False Negative（見逃し）**: 危険なのに安全と判定すること。**これを防ぐことが最優先**。

---
